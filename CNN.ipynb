{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598892355211",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 8000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_idg=ImageDataGenerator(rescale=1./250,zoom_range=0.2,horizontal_flip=True,shear_range=0.2)\n",
    "test_idg=ImageDataGenerator(rescale=1./250)\n",
    "training_set=train_idg.flow_from_directory('dataset/training_set',target_size=(64,64),batch_size=32,class_mode='binary')\n",
    "valid_set=test_idg.flow_from_directory('dataset/test_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/clown/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "\n",
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(units=128,activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/clown/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Validating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/25\n250/250 [==============================] - 32s 127ms/step - loss: 0.6804 - acc: 0.5646 - val_loss: 0.6301 - val_acc: 0.6725\nEpoch 2/25\n250/250 [==============================] - 32s 130ms/step - loss: 0.6150 - acc: 0.6629 - val_loss: 0.5546 - val_acc: 0.7290\nEpoch 3/25\n250/250 [==============================] - 32s 130ms/step - loss: 0.5665 - acc: 0.7019 - val_loss: 0.5362 - val_acc: 0.7430\nEpoch 4/25\n250/250 [==============================] - 33s 130ms/step - loss: 0.5350 - acc: 0.7352 - val_loss: 0.4981 - val_acc: 0.7660\nEpoch 5/25\n250/250 [==============================] - 33s 130ms/step - loss: 0.5121 - acc: 0.7484 - val_loss: 0.5014 - val_acc: 0.7650\nEpoch 6/25\n250/250 [==============================] - 34s 136ms/step - loss: 0.4895 - acc: 0.7600 - val_loss: 0.4866 - val_acc: 0.7650\nEpoch 7/25\n250/250 [==============================] - 36s 144ms/step - loss: 0.4819 - acc: 0.7722 - val_loss: 0.4870 - val_acc: 0.7745\nEpoch 8/25\n250/250 [==============================] - 36s 145ms/step - loss: 0.4653 - acc: 0.7824 - val_loss: 0.4927 - val_acc: 0.7575\nEpoch 9/25\n250/250 [==============================] - 38s 151ms/step - loss: 0.4501 - acc: 0.7864 - val_loss: 0.4350 - val_acc: 0.7975\nEpoch 10/25\n250/250 [==============================] - 38s 151ms/step - loss: 0.4416 - acc: 0.7947 - val_loss: 0.4469 - val_acc: 0.8030\nEpoch 11/25\n250/250 [==============================] - 37s 147ms/step - loss: 0.4255 - acc: 0.8046 - val_loss: 0.4391 - val_acc: 0.7970\nEpoch 12/25\n250/250 [==============================] - 33s 133ms/step - loss: 0.4145 - acc: 0.8099 - val_loss: 0.4561 - val_acc: 0.7885\nEpoch 13/25\n250/250 [==============================] - 36s 143ms/step - loss: 0.4105 - acc: 0.8067 - val_loss: 0.4544 - val_acc: 0.7930\nEpoch 14/25\n250/250 [==============================] - 37s 150ms/step - loss: 0.4023 - acc: 0.8125 - val_loss: 0.4779 - val_acc: 0.7760\nEpoch 15/25\n250/250 [==============================] - 35s 140ms/step - loss: 0.3998 - acc: 0.8183 - val_loss: 0.4501 - val_acc: 0.7965\nEpoch 16/25\n250/250 [==============================] - 36s 142ms/step - loss: 0.3809 - acc: 0.8282 - val_loss: 0.4188 - val_acc: 0.8235\nEpoch 17/25\n250/250 [==============================] - 35s 141ms/step - loss: 0.3784 - acc: 0.8336 - val_loss: 0.4188 - val_acc: 0.8120\nEpoch 18/25\n250/250 [==============================] - 35s 142ms/step - loss: 0.3658 - acc: 0.8357 - val_loss: 0.4340 - val_acc: 0.8050\nEpoch 19/25\n250/250 [==============================] - 35s 141ms/step - loss: 0.3614 - acc: 0.8382 - val_loss: 0.4409 - val_acc: 0.8055\nEpoch 20/25\n250/250 [==============================] - 34s 137ms/step - loss: 0.3587 - acc: 0.8378 - val_loss: 0.4444 - val_acc: 0.8055\nEpoch 21/25\n250/250 [==============================] - 38s 152ms/step - loss: 0.3510 - acc: 0.8445 - val_loss: 0.4103 - val_acc: 0.8225\nEpoch 22/25\n250/250 [==============================] - 44s 177ms/step - loss: 0.3426 - acc: 0.8493 - val_loss: 0.4078 - val_acc: 0.8230\nEpoch 23/25\n250/250 [==============================] - 45s 181ms/step - loss: 0.3327 - acc: 0.8583 - val_loss: 0.4409 - val_acc: 0.8170\nEpoch 24/25\n250/250 [==============================] - 43s 170ms/step - loss: 0.3226 - acc: 0.8568 - val_loss: 0.4411 - val_acc: 0.8230\nEpoch 25/25\n250/250 [==============================] - 59s 238ms/step - loss: 0.3290 - acc: 0.8559 - val_loss: 0.4260 - val_acc: 0.8160\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2424499110>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=valid_set,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Custom Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dog\n"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img('dataset/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
    "img=image.img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "y=cnn.predict(img)\n",
    "training_set.class_indices\n",
    "if y[0][0]==1:\n",
    "    print('dog')\n",
    "else:\n",
    "    print('cat')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cat\n"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img('dataset/single_prediction/cat_or_dog_2.jpg',target_size=(64,64))\n",
    "img=image.img_to_array(img)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "y=cnn.predict(img)\n",
    "training_set.class_indices\n",
    "if y[0][0]==1:\n",
    "    print('dog')\n",
    "else:\n",
    "    print('cat')  "
   ]
  }
 ]
}